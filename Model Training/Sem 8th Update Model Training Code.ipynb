{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6eac36fe-fc29-4c1e-9c78-c8576f986a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\anaconda3\\lib\\site-packages (4.43.1)\n",
      "Requirement already satisfied: datasets in c:\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: torch in c:\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\anaconda3\\lib\\site-packages (from transformers) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75257634-3426-451d-ad82-af9194f0372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4066e8a0-e7fa-4ab9-8758-ee61eb2a53bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>2</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>2</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>2</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>2</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>2</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID        Topic  Sentiment  \\\n",
       "0  2401  Borderlands          2   \n",
       "1  2401  Borderlands          2   \n",
       "2  2401  Borderlands          2   \n",
       "3  2401  Borderlands          2   \n",
       "4  2401  Borderlands          2   \n",
       "\n",
       "                                                Text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (update path if needed)\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Harsh Tripathi\\\\Documents\\\\Whatsapp Project 8 sem\\\\Dataset\\\\twitter_training.csv\", delimiter=\",\", header=None, names=[\"ID\", \"Topic\", \"Sentiment\", \"Text\"])\n",
    "\n",
    "# Remove 'Irrelevant' labeled texts\n",
    "df = df[df[\"Sentiment\"] != \"Irrelevant\"].reset_index(drop=True)\n",
    "\n",
    "# Encode sentiment labels (Positive=2, Neutral=1, Negative=0)\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Sentiment\"] = label_encoder.fit_transform(df[\"Sentiment\"])\n",
    "\n",
    "# Check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d884e64-607d-4931-88c5-f4d4c9c5c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "True    828\n",
      "Name: count, dtype: int64\n",
      "Sample Text: BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine…\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Ensure all text values are strings\n",
    "df[\"Text\"] = df[\"Text\"].astype(str)\n",
    "\n",
    "# Check if any non-string values exist\n",
    "print(df[\"Text\"].apply(lambda x: isinstance(x, str)).value_counts())\n",
    "\n",
    "# Print a sample text to confirm it's clean\n",
    "print(\"Sample Text:\", df[\"Text\"].iloc[0])\n",
    "print(type(df[\"Text\"].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ab7067e-7607-4e84-85bf-ac92e87a2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11a21170-9756-467c-8c9c-3ec0aacad02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        text = str(self.texts[idx])  # Ensure text is a string\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if pd.isna(text) or text.strip() == \"\":  # Handle empty/missing text\n",
    "            text = \"empty text\"  \n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41a5469f-b4cd-4c54-b02a-876f74e476b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text and labels to list\n",
    "texts = df[\"Text\"].tolist()\n",
    "labels = df[\"Sentiment\"].tolist()\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = SentimentDataset(texts, labels, tokenizer)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Check dataset size\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60ec9c16-1738-46ad-b97c-4161bb654600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.dropout(outputs.last_hidden_state[:, 0, :])  # CLS token output\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35239119-305f-4964-b05a-4756cc1902b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = SentimentClassifier(num_classes=3).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d1907ba-570e-4094-bb7e-4e9f59614c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1050\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True\n",
    "print(torch.cuda.device_count())  # Number of GPUs available\n",
    "print(torch.cuda.get_device_name(0))  # GPU name\n",
    "print(torch.version.cuda)  # CUDA version PyTorch is using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eeda5f-e535-40d8-a30b-00b644f365d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3  # You can change this\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "602efc67-0a5e-437a-aa41-319a49c63992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./distilbert_sentiment_model\\\\tokenizer_config.json',\n",
       " './distilbert_sentiment_model\\\\special_tokens_map.json',\n",
       " './distilbert_sentiment_model\\\\vocab.txt',\n",
       " './distilbert_sentiment_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"distilbert_sentiment_model.pth\")\n",
    "print(\"Model training complete and saved!\")\n",
    "\n",
    "# Save the tokenizer separately\n",
    "tokenizer.save_pretrained(\"./distilbert_sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0e0b4-3afd-437d-89f4-fd8b658f88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Define the number of classes (adjust this based on your dataset)\n",
    "num_classes = 3  # Example: Positive, Negative, Neutral\n",
    "\n",
    "# Recreate the model architecture with the correct number of classes\n",
    "model = SentimentClassifier(num_classes=num_classes)  \n",
    "model.load_state_dict(torch.load(\"distilbert_sentiment_model.pth\", weights_only=True))\n",
    "\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./distilbert_sentiment_model\")\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec8af50b-3252-41c7-9a9b-16b16d119076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./distilbert_sentiment_model\")\n",
    "\n",
    "# Load the trained model\n",
    "model = SentimentClassifier(num_classes=3)  # Ensure correct num_classes\n",
    "model.load_state_dict(torch.load(\"distilbert_sentiment_model.pth\", weights_only=True))\n",
    "model.eval()  # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9687d2d1-b4e9-4384-b780-a1ccaecdef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Define SentimentClassifier model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "# Define class mapping\n",
    "sentiment_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./distilbert_sentiment_model\")\n",
    "\n",
    "# Load model\n",
    "model = SentimentClassifier(num_classes=3)\n",
    "\n",
    "# Load state_dict and rename keys if needed\n",
    "state_dict = torch.load(\"distilbert_sentiment_model.pth\", map_location=torch.device(\"cpu\"), weights_only=True)\n",
    "\n",
    "\n",
    "# Rename keys from \"fc\" to \"classifier\" if needed\n",
    "new_state_dict = {k.replace(\"fc\", \"classifier\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict, strict=False)  # Allow flexible loading\n",
    "\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load validation data\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Harsh Tripathi\\\\Documents\\\\Whatsapp Project 8 sem\\\\Dataset\\\\twitter_validation.csv\", \n",
    "                 sep=\"\\t\", header=None, names=[\"ID\", \"Category\", \"Sentiment\", \"Text\"])\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Harsh Tripathi\\\\Documents\\\\Whatsapp Project 8 sem\\\\Dataset\\\\twitter_validation.csv\", sep=\",\", header=None, names=[\"ID\", \"Category\", \"Sentiment\", \"Text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80b44602-85a3-40d8-87fd-9dd718247b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID   Category Sentiment  \\\n",
      "0   352     Amazon   Neutral   \n",
      "1  8312  Microsoft  Negative   \n",
      "2  4371      CS-GO  Negative   \n",
      "3  4433     Google   Neutral   \n",
      "4  6273       FIFA  Negative   \n",
      "\n",
      "                                                Text Predicted Sentiment  \n",
      "0  BBC News - Amazon boss Jeff Bezos rejects clai...             Neutral  \n",
      "1  @Microsoft Why do I pay for WORD when it funct...            Negative  \n",
      "2  CSGO matchmaking is so full of closet hacking,...            Negative  \n",
      "3  Now the President is slapping Americans in the...             Neutral  \n",
      "4  Hi @EAHelp I’ve had Madeleine McCann in my cel...            Negative  \n"
     ]
    }
   ],
   "source": [
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "247aa2b3-d8ff-4cfd-974a-fd5382d34c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete! Results saved to predicted_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Remove \"Irrelevant\" rows\n",
    "df = df[df[\"Sentiment\"].isin([\"Positive\", \"Negative\", \"Neutral\"])]\n",
    "\n",
    "# Predict sentiment\n",
    "predictions = []\n",
    "for text in df[\"Text\"]:\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        probs = softmax(outputs, dim=1)  \n",
    "        predicted_class = torch.argmax(probs, dim=1).item()  \n",
    "    \n",
    "    predictions.append(sentiment_mapping[predicted_class])\n",
    "\n",
    "# Save results\n",
    "df[\"Predicted Sentiment\"] = predictions\n",
    "df.to_csv(\"predicted_results.csv\", index=False)\n",
    "\n",
    "print(\"Prediction complete! Results saved to predicted_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e18a258-6031-444d-ae2d-09ae9c6d3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 97.71%\n",
      "Incorrect Predictions:\n",
      "                                                  Text Sentiment  \\\n",
      "43                I’m addicted to call of duty mobile😅  Negative   \n",
      "60   Seems like #Playstation has the marketing deal...   Neutral   \n",
      "78   GM Fam!!! hope you are all up and being great ...   Neutral   \n",
      "80   Leaked memo excoriates #Facebook’s ‘slapdash a...  Negative   \n",
      "131  I didn't have massive success in #IndieApril b...   Neutral   \n",
      "181  Plague of Corruption is #1 on Amazon and # 3 o...  Negative   \n",
      "269  #WorldCupAtHome: Five African matches you woul...  Positive   \n",
      "301  Shipped first GPU-enabled production code thro...   Neutral   \n",
      "322                                           Mori😻😻😻😻   Neutral   \n",
      "369  Wine drunk playing the new Borderlands 😩\\n\\nGo...   Neutral   \n",
      "382  This is about as far as I can go with it for t...   Neutral   \n",
      "434  Absolutely love my amazing sister who has made...   Neutral   \n",
      "450  My main reason for wanting the #PS5 is because...   Neutral   \n",
      "465  #writingcommunity I just want to take a second...  Positive   \n",
      "486  I tried to do some of purple invasion stuff to...   Neutral   \n",
      "487  While it's true that #GhostReconBreakpoint nee...   Neutral   \n",
      "525  Ummm Wth....\\n#ApexLegends pic.twitter.com/eXc...  Negative   \n",
      "532                  So #Maria was playing FIFA today.   Neutral   \n",
      "676  #Madden20 should make cross play a thing in th...  Negative   \n",
      "\n",
      "    Predicted Sentiment  \n",
      "43             Positive  \n",
      "60             Positive  \n",
      "78             Positive  \n",
      "80              Neutral  \n",
      "131            Positive  \n",
      "181             Neutral  \n",
      "269             Neutral  \n",
      "301            Positive  \n",
      "322            Positive  \n",
      "369            Positive  \n",
      "382            Positive  \n",
      "434            Positive  \n",
      "450            Positive  \n",
      "465             Neutral  \n",
      "486            Positive  \n",
      "487            Positive  \n",
      "525             Neutral  \n",
      "532            Positive  \n",
      "676            Positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"predicted_results.csv\")\n",
    "\n",
    "# Compare actual vs. predicted sentiment\n",
    "df[\"Correct\"] = df[\"Sentiment\"] == df[\"Predicted Sentiment\"]\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = df[\"Correct\"].mean() * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Show incorrect predictions\n",
    "incorrect_predictions = df[df[\"Correct\"] == False]\n",
    "print(\"Incorrect Predictions:\")\n",
    "print(incorrect_predictions[[\"Text\", \"Sentiment\", \"Predicted Sentiment\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c82a4f00-bb0e-44d6-bbb9-f9921dff4377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment\n",
      "Positive    289\n",
      "Neutral     278\n",
      "Negative    261\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Predicted Sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfb706b9-a33b-4b69-b3d3-34454a89a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 97.71%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the predicted results\n",
    "df = pd.read_csv(\"predicted_results.csv\")\n",
    "\n",
    "# Drop any NaN values (if present)\n",
    "df.dropna(subset=[\"Sentiment\", \"Predicted Sentiment\"], inplace=True)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (df[\"Sentiment\"] == df[\"Predicted Sentiment\"]).mean() * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41871f35-b742-4b55-a952-13af5cca0e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect predictions: 19\n",
      "                                                  Text Sentiment  \\\n",
      "43                I’m addicted to call of duty mobile😅  Negative   \n",
      "60   Seems like #Playstation has the marketing deal...   Neutral   \n",
      "78   GM Fam!!! hope you are all up and being great ...   Neutral   \n",
      "80   Leaked memo excoriates #Facebook’s ‘slapdash a...  Negative   \n",
      "131  I didn't have massive success in #IndieApril b...   Neutral   \n",
      "181  Plague of Corruption is #1 on Amazon and # 3 o...  Negative   \n",
      "269  #WorldCupAtHome: Five African matches you woul...  Positive   \n",
      "301  Shipped first GPU-enabled production code thro...   Neutral   \n",
      "322                                           Mori😻😻😻😻   Neutral   \n",
      "369  Wine drunk playing the new Borderlands 😩\\n\\nGo...   Neutral   \n",
      "\n",
      "    Predicted Sentiment  \n",
      "43             Positive  \n",
      "60             Positive  \n",
      "78             Positive  \n",
      "80              Neutral  \n",
      "131            Positive  \n",
      "181             Neutral  \n",
      "269             Neutral  \n",
      "301            Positive  \n",
      "322            Positive  \n",
      "369            Positive  \n"
     ]
    }
   ],
   "source": [
    "incorrect_df = df[df[\"Sentiment\"] != df[\"Predicted Sentiment\"]]\n",
    "print(f\"Number of incorrect predictions: {len(incorrect_df)}\")\n",
    "print(incorrect_df[[\"Text\", \"Sentiment\", \"Predicted Sentiment\"]].head(10))  # Show first 10 errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fdfdcac-91e3-457a-9603-07f15937d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment\n",
      "Positive    289\n",
      "Neutral     278\n",
      "Negative    261\n",
      "Name: count, dtype: int64\n",
      "Sentiment\n",
      "Neutral     285\n",
      "Positive    277\n",
      "Negative    266\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Predicted Sentiment\"].value_counts())\n",
    "print(df[\"Sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cee69c4-891b-42d6-a621-b13aba65c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b606ba2-fa9e-4688-acfb-1ad00a5fcc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 35.14%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       266\n",
      "     Neutral       0.59      0.12      0.19       285\n",
      "    Positive       0.33      0.93      0.49       277\n",
      "\n",
      "    accuracy                           0.35       828\n",
      "   macro avg       0.31      0.35      0.23       828\n",
      "weighted avg       0.31      0.35      0.23       828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the predicted results\n",
    "df = pd.read_csv(\"predicted_results.csv\")\n",
    "\n",
    "# Ensure there are no NaN values\n",
    "df.dropna(subset=[\"Sentiment\", \"Predicted Sentiment\"], inplace=True)\n",
    "\n",
    "# Define class mapping (ensure your labels match exactly)\n",
    "sentiment_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "\n",
    "# Convert Sentiment labels to numeric values\n",
    "df[\"Sentiment\"] = df[\"Sentiment\"].map(sentiment_mapping)\n",
    "df[\"Predicted Sentiment\"] = df[\"Predicted Sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(df[\"Sentiment\"], df[\"Predicted Sentiment\"])\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Compute Precision, Recall, and F1-score\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df[\"Sentiment\"], df[\"Predicted Sentiment\"], target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952d7bf-963a-4162-99c7-d7bd137f4c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
